{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Trabalho Final Deep Learning - Exerc√≠cio 05.1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "34dfee18d5f4a96df9a8fcc719c91cf50e8ed50de2aa108bf45cd20982063274"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# Link Trabalho Final : https://www.dropbox.com/s/3fla2xuc8t9xba2/Deep%20Learning%20-%20Lista%20de%20Exerc%C3%ADcios%20v1.4.pdf?dl=0"
      ],
      "outputs": [],
      "metadata": {
        "id": "IL4uIJ3BHj5h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "from sklearn import datasets\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import keras\r\n",
        "from keras.models import Sequential,load_model\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D\r\n",
        "from keras.utils import np_utils\r\n",
        "#from keras.utils import plot_model\r\n",
        "from keras.utils.vis_utils import plot_model\r\n",
        "from keras.utils.np_utils import  to_categorical\r\n",
        "from keras.callbacks import ModelCheckpoint   "
      ],
      "outputs": [],
      "metadata": {
        "id": "HfU7ax3LH4MS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# from google.colab import drive\r\n",
        "# drive.mount('/content/drive')\r\n",
        "file_path = 'D:\\__Projetos_\\_MBA\\DeepLearning\\deep_learning_final_17ia\\dados\\DatasetExercicio5.1.csv'\r\n",
        "file_path2 = 'D:\\__Projetos_\\_MBA\\DeepLearning\\deep_learning_final_17ia\\dados\\Classes-Exercicio5.1.csv'\r\n",
        "\r\n",
        "if os.path.exists(file_path) :\r\n",
        "    print(\"Arquivo Existe\")\r\n",
        "if os.path.exists(file_path2) :\r\n",
        "    print(\"Arquivo Existe\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo Existe\n",
            "Arquivo Existe\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C20zZ__57wj",
        "outputId": "470cd91e-51aa-46cb-9d86-5bf4c7c52285"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# !ls '/content/drive/MyDrive/__FIAP/MBA - 17IA/Deep Learning & Reinforcement Learning/dados_trabalho_final/DadosSpotify.csv'"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlXbbADJ58z9",
        "outputId": "29a4cead-0407-416c-df78-81d6ac113500"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "df = pd.read_csv(file_path,sep=';')\r\n",
        "\r\n",
        "print(df.shape)\r\n",
        "df.head(5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 17)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -0.732337 -0.460087  0.410588  1.387655  1.549960 -0.309028 -0.119034   \n",
              "1 -1.697668 -3.658057 -0.067462 -0.307627 -3.257361  3.018813  0.506056   \n",
              "2 -0.009419 -2.079725  0.695339  1.395909 -1.152059 -0.149841 -1.748309   \n",
              "3 -0.955029  2.413873 -0.239355  0.296029  0.785301 -2.146341  1.792001   \n",
              "4  2.282446  0.764661  0.385960 -3.203398  0.165334  2.816127 -0.592895   \n",
              "\n",
              "          7         8         9        10        11        12        13  \\\n",
              "0 -1.710895 -2.103701  0.270298 -0.951528 -1.738395  2.242746 -0.062398   \n",
              "1 -1.943546 -0.781291 -1.054938 -0.903841 -0.971778  0.725666 -0.288371   \n",
              "2  0.663311  0.243399 -0.468567 -1.793045  0.313092  0.156787  0.646463   \n",
              "3  0.023154 -0.379947  1.025835  0.083103  1.352882  0.061962  0.043511   \n",
              "4 -0.460681  1.613249 -0.383905  1.345218  0.173645  1.299997 -0.356091   \n",
              "\n",
              "         14        15        16  \n",
              "0  3.600965  0.506660 -0.351065  \n",
              "1  2.136540 -0.172262 -3.538182  \n",
              "2  0.872121 -0.876460 -0.159286  \n",
              "3 -1.387151  1.786397  0.813789  \n",
              "4 -2.358184  0.142573 -1.503465  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.732337</td>\n",
              "      <td>-0.460087</td>\n",
              "      <td>0.410588</td>\n",
              "      <td>1.387655</td>\n",
              "      <td>1.549960</td>\n",
              "      <td>-0.309028</td>\n",
              "      <td>-0.119034</td>\n",
              "      <td>-1.710895</td>\n",
              "      <td>-2.103701</td>\n",
              "      <td>0.270298</td>\n",
              "      <td>-0.951528</td>\n",
              "      <td>-1.738395</td>\n",
              "      <td>2.242746</td>\n",
              "      <td>-0.062398</td>\n",
              "      <td>3.600965</td>\n",
              "      <td>0.506660</td>\n",
              "      <td>-0.351065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.697668</td>\n",
              "      <td>-3.658057</td>\n",
              "      <td>-0.067462</td>\n",
              "      <td>-0.307627</td>\n",
              "      <td>-3.257361</td>\n",
              "      <td>3.018813</td>\n",
              "      <td>0.506056</td>\n",
              "      <td>-1.943546</td>\n",
              "      <td>-0.781291</td>\n",
              "      <td>-1.054938</td>\n",
              "      <td>-0.903841</td>\n",
              "      <td>-0.971778</td>\n",
              "      <td>0.725666</td>\n",
              "      <td>-0.288371</td>\n",
              "      <td>2.136540</td>\n",
              "      <td>-0.172262</td>\n",
              "      <td>-3.538182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.009419</td>\n",
              "      <td>-2.079725</td>\n",
              "      <td>0.695339</td>\n",
              "      <td>1.395909</td>\n",
              "      <td>-1.152059</td>\n",
              "      <td>-0.149841</td>\n",
              "      <td>-1.748309</td>\n",
              "      <td>0.663311</td>\n",
              "      <td>0.243399</td>\n",
              "      <td>-0.468567</td>\n",
              "      <td>-1.793045</td>\n",
              "      <td>0.313092</td>\n",
              "      <td>0.156787</td>\n",
              "      <td>0.646463</td>\n",
              "      <td>0.872121</td>\n",
              "      <td>-0.876460</td>\n",
              "      <td>-0.159286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.955029</td>\n",
              "      <td>2.413873</td>\n",
              "      <td>-0.239355</td>\n",
              "      <td>0.296029</td>\n",
              "      <td>0.785301</td>\n",
              "      <td>-2.146341</td>\n",
              "      <td>1.792001</td>\n",
              "      <td>0.023154</td>\n",
              "      <td>-0.379947</td>\n",
              "      <td>1.025835</td>\n",
              "      <td>0.083103</td>\n",
              "      <td>1.352882</td>\n",
              "      <td>0.061962</td>\n",
              "      <td>0.043511</td>\n",
              "      <td>-1.387151</td>\n",
              "      <td>1.786397</td>\n",
              "      <td>0.813789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.282446</td>\n",
              "      <td>0.764661</td>\n",
              "      <td>0.385960</td>\n",
              "      <td>-3.203398</td>\n",
              "      <td>0.165334</td>\n",
              "      <td>2.816127</td>\n",
              "      <td>-0.592895</td>\n",
              "      <td>-0.460681</td>\n",
              "      <td>1.613249</td>\n",
              "      <td>-0.383905</td>\n",
              "      <td>1.345218</td>\n",
              "      <td>0.173645</td>\n",
              "      <td>1.299997</td>\n",
              "      <td>-0.356091</td>\n",
              "      <td>-2.358184</td>\n",
              "      <td>0.142573</td>\n",
              "      <td>-1.503465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "5atbqVkS6DFr",
        "outputId": "71908327-91a3-40dc-f979-a4ff07fd466e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "df2 = pd.read_csv(file_path2)\r\n",
        "\r\n",
        "print(df2.shape)\r\n",
        "df2.head(5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0\n",
              "0  7\n",
              "1  4\n",
              "2  6\n",
              "3  5\n",
              "4  1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uouIGEHKbb0F",
        "outputId": "66b82d2f-dcd6-44b6-ef35-b33ad261936d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "concat = pd.concat([df,df2],axis=1)\r\n",
        "\r\n",
        "print(concat.shape)\r\n",
        "concat.head(10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 18)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -0.732337 -0.460087  0.410588  1.387655  1.549960 -0.309028 -0.119034   \n",
              "1 -1.697668 -3.658057 -0.067462 -0.307627 -3.257361  3.018813  0.506056   \n",
              "2 -0.009419 -2.079725  0.695339  1.395909 -1.152059 -0.149841 -1.748309   \n",
              "3 -0.955029  2.413873 -0.239355  0.296029  0.785301 -2.146341  1.792001   \n",
              "4  2.282446  0.764661  0.385960 -3.203398  0.165334  2.816127 -0.592895   \n",
              "5 -0.713816 -0.616574  0.160519 -1.692975  0.980060 -0.193303 -0.331494   \n",
              "6  0.742155 -1.573932 -0.234802 -1.241070  1.673690  2.130111  0.281394   \n",
              "7  0.873751  0.195256 -0.168088 -2.524054 -1.916243  3.253399 -1.211223   \n",
              "8  0.589379  0.258247  1.091963 -3.493732  2.807936  5.454892 -0.311375   \n",
              "9 -1.879840  4.008358  1.127651 -0.689849  0.429449 -1.008465  0.405372   \n",
              "\n",
              "          7         8         9        10        11        12        13  \\\n",
              "0 -1.710895 -2.103701  0.270298 -0.951528 -1.738395  2.242746 -0.062398   \n",
              "1 -1.943546 -0.781291 -1.054938 -0.903841 -0.971778  0.725666 -0.288371   \n",
              "2  0.663311  0.243399 -0.468567 -1.793045  0.313092  0.156787  0.646463   \n",
              "3  0.023154 -0.379947  1.025835  0.083103  1.352882  0.061962  0.043511   \n",
              "4 -0.460681  1.613249 -0.383905  1.345218  0.173645  1.299997 -0.356091   \n",
              "5  2.858454 -0.604789  2.841696 -0.088143 -1.129659  2.319393  0.022831   \n",
              "6 -1.245286  0.632090 -0.803289 -0.104619 -0.840556  1.980110 -0.612544   \n",
              "7  1.857237  3.269247  0.196898  2.377251 -0.217932 -2.951695 -0.222007   \n",
              "8 -0.416744 -0.007799 -0.226312  4.916241  1.222347 -0.479960  0.212871   \n",
              "9 -2.285937  2.139779 -0.612271  2.637620 -0.059653 -4.330012 -0.730626   \n",
              "\n",
              "         14        15        16  0  \n",
              "0  3.600965  0.506660 -0.351065  7  \n",
              "1  2.136540 -0.172262 -3.538182  4  \n",
              "2  0.872121 -0.876460 -0.159286  6  \n",
              "3 -1.387151  1.786397  0.813789  5  \n",
              "4 -2.358184  0.142573 -1.503465  1  \n",
              "5  0.634337 -0.508594  2.581261  0  \n",
              "6  2.969955 -0.387794  0.816913  2  \n",
              "7 -5.504074 -0.972476 -2.171356  5  \n",
              "8  0.729138 -1.279104 -1.467671  3  \n",
              "9 -3.437425  1.726261  0.411220  2  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.732337</td>\n",
              "      <td>-0.460087</td>\n",
              "      <td>0.410588</td>\n",
              "      <td>1.387655</td>\n",
              "      <td>1.549960</td>\n",
              "      <td>-0.309028</td>\n",
              "      <td>-0.119034</td>\n",
              "      <td>-1.710895</td>\n",
              "      <td>-2.103701</td>\n",
              "      <td>0.270298</td>\n",
              "      <td>-0.951528</td>\n",
              "      <td>-1.738395</td>\n",
              "      <td>2.242746</td>\n",
              "      <td>-0.062398</td>\n",
              "      <td>3.600965</td>\n",
              "      <td>0.506660</td>\n",
              "      <td>-0.351065</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.697668</td>\n",
              "      <td>-3.658057</td>\n",
              "      <td>-0.067462</td>\n",
              "      <td>-0.307627</td>\n",
              "      <td>-3.257361</td>\n",
              "      <td>3.018813</td>\n",
              "      <td>0.506056</td>\n",
              "      <td>-1.943546</td>\n",
              "      <td>-0.781291</td>\n",
              "      <td>-1.054938</td>\n",
              "      <td>-0.903841</td>\n",
              "      <td>-0.971778</td>\n",
              "      <td>0.725666</td>\n",
              "      <td>-0.288371</td>\n",
              "      <td>2.136540</td>\n",
              "      <td>-0.172262</td>\n",
              "      <td>-3.538182</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.009419</td>\n",
              "      <td>-2.079725</td>\n",
              "      <td>0.695339</td>\n",
              "      <td>1.395909</td>\n",
              "      <td>-1.152059</td>\n",
              "      <td>-0.149841</td>\n",
              "      <td>-1.748309</td>\n",
              "      <td>0.663311</td>\n",
              "      <td>0.243399</td>\n",
              "      <td>-0.468567</td>\n",
              "      <td>-1.793045</td>\n",
              "      <td>0.313092</td>\n",
              "      <td>0.156787</td>\n",
              "      <td>0.646463</td>\n",
              "      <td>0.872121</td>\n",
              "      <td>-0.876460</td>\n",
              "      <td>-0.159286</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.955029</td>\n",
              "      <td>2.413873</td>\n",
              "      <td>-0.239355</td>\n",
              "      <td>0.296029</td>\n",
              "      <td>0.785301</td>\n",
              "      <td>-2.146341</td>\n",
              "      <td>1.792001</td>\n",
              "      <td>0.023154</td>\n",
              "      <td>-0.379947</td>\n",
              "      <td>1.025835</td>\n",
              "      <td>0.083103</td>\n",
              "      <td>1.352882</td>\n",
              "      <td>0.061962</td>\n",
              "      <td>0.043511</td>\n",
              "      <td>-1.387151</td>\n",
              "      <td>1.786397</td>\n",
              "      <td>0.813789</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.282446</td>\n",
              "      <td>0.764661</td>\n",
              "      <td>0.385960</td>\n",
              "      <td>-3.203398</td>\n",
              "      <td>0.165334</td>\n",
              "      <td>2.816127</td>\n",
              "      <td>-0.592895</td>\n",
              "      <td>-0.460681</td>\n",
              "      <td>1.613249</td>\n",
              "      <td>-0.383905</td>\n",
              "      <td>1.345218</td>\n",
              "      <td>0.173645</td>\n",
              "      <td>1.299997</td>\n",
              "      <td>-0.356091</td>\n",
              "      <td>-2.358184</td>\n",
              "      <td>0.142573</td>\n",
              "      <td>-1.503465</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.713816</td>\n",
              "      <td>-0.616574</td>\n",
              "      <td>0.160519</td>\n",
              "      <td>-1.692975</td>\n",
              "      <td>0.980060</td>\n",
              "      <td>-0.193303</td>\n",
              "      <td>-0.331494</td>\n",
              "      <td>2.858454</td>\n",
              "      <td>-0.604789</td>\n",
              "      <td>2.841696</td>\n",
              "      <td>-0.088143</td>\n",
              "      <td>-1.129659</td>\n",
              "      <td>2.319393</td>\n",
              "      <td>0.022831</td>\n",
              "      <td>0.634337</td>\n",
              "      <td>-0.508594</td>\n",
              "      <td>2.581261</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.742155</td>\n",
              "      <td>-1.573932</td>\n",
              "      <td>-0.234802</td>\n",
              "      <td>-1.241070</td>\n",
              "      <td>1.673690</td>\n",
              "      <td>2.130111</td>\n",
              "      <td>0.281394</td>\n",
              "      <td>-1.245286</td>\n",
              "      <td>0.632090</td>\n",
              "      <td>-0.803289</td>\n",
              "      <td>-0.104619</td>\n",
              "      <td>-0.840556</td>\n",
              "      <td>1.980110</td>\n",
              "      <td>-0.612544</td>\n",
              "      <td>2.969955</td>\n",
              "      <td>-0.387794</td>\n",
              "      <td>0.816913</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.873751</td>\n",
              "      <td>0.195256</td>\n",
              "      <td>-0.168088</td>\n",
              "      <td>-2.524054</td>\n",
              "      <td>-1.916243</td>\n",
              "      <td>3.253399</td>\n",
              "      <td>-1.211223</td>\n",
              "      <td>1.857237</td>\n",
              "      <td>3.269247</td>\n",
              "      <td>0.196898</td>\n",
              "      <td>2.377251</td>\n",
              "      <td>-0.217932</td>\n",
              "      <td>-2.951695</td>\n",
              "      <td>-0.222007</td>\n",
              "      <td>-5.504074</td>\n",
              "      <td>-0.972476</td>\n",
              "      <td>-2.171356</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.589379</td>\n",
              "      <td>0.258247</td>\n",
              "      <td>1.091963</td>\n",
              "      <td>-3.493732</td>\n",
              "      <td>2.807936</td>\n",
              "      <td>5.454892</td>\n",
              "      <td>-0.311375</td>\n",
              "      <td>-0.416744</td>\n",
              "      <td>-0.007799</td>\n",
              "      <td>-0.226312</td>\n",
              "      <td>4.916241</td>\n",
              "      <td>1.222347</td>\n",
              "      <td>-0.479960</td>\n",
              "      <td>0.212871</td>\n",
              "      <td>0.729138</td>\n",
              "      <td>-1.279104</td>\n",
              "      <td>-1.467671</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-1.879840</td>\n",
              "      <td>4.008358</td>\n",
              "      <td>1.127651</td>\n",
              "      <td>-0.689849</td>\n",
              "      <td>0.429449</td>\n",
              "      <td>-1.008465</td>\n",
              "      <td>0.405372</td>\n",
              "      <td>-2.285937</td>\n",
              "      <td>2.139779</td>\n",
              "      <td>-0.612271</td>\n",
              "      <td>2.637620</td>\n",
              "      <td>-0.059653</td>\n",
              "      <td>-4.330012</td>\n",
              "      <td>-0.730626</td>\n",
              "      <td>-3.437425</td>\n",
              "      <td>1.726261</td>\n",
              "      <td>0.411220</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "concat.corr()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6  \\\n",
              "0   1.000000 -0.001899 -0.003644 -0.001619 -0.000218  0.000595  0.000947   \n",
              "1  -0.001899  1.000000 -0.013619  0.026846  0.156286 -0.532279 -0.011862   \n",
              "2  -0.003644 -0.013619  1.000000  0.006683 -0.002436  0.000619  0.013646   \n",
              "3  -0.001619  0.026846  0.006683  1.000000  0.025842 -0.493383  0.002845   \n",
              "4  -0.000218  0.156286 -0.002436  0.025842  1.000000  0.356500 -0.008852   \n",
              "5   0.000595 -0.532279  0.000619 -0.493383  0.356500  1.000000  0.004947   \n",
              "6   0.000947 -0.011862  0.013646  0.002845 -0.008852  0.004947  1.000000   \n",
              "7   0.001373 -0.119522  0.008997 -0.063115 -0.088741  0.006155 -0.004530   \n",
              "8   0.011192 -0.031345  0.006984 -0.130317 -0.093688  0.106089 -0.001549   \n",
              "9  -0.006915  0.009578  0.000782  0.004896 -0.011115 -0.014223 -0.001331   \n",
              "10 -0.002013  0.025178 -0.008695 -0.595702  0.449010  0.692708 -0.007098   \n",
              "11  0.013629  0.001179 -0.002614  0.003101  0.005249 -0.001059 -0.001173   \n",
              "12 -0.003676 -0.003694  0.001377  0.137438  0.034566 -0.265431  0.007710   \n",
              "13 -0.000692 -0.000831 -0.001127  0.004664 -0.011399 -0.009599 -0.001390   \n",
              "14 -0.003278 -0.528225  0.002603  0.087543  0.352633  0.294021  0.004010   \n",
              "15 -0.002583  0.006554  0.004943  0.005941 -0.004484 -0.010747  0.003445   \n",
              "16  0.005674  0.144510  0.004756 -0.088239 -0.000975 -0.510255 -0.012244   \n",
              "0   0.006847 -0.071429  0.004059  0.040137 -0.002967  0.031676  0.000622   \n",
              "\n",
              "           7         8         9        10        11        12        13  \\\n",
              "0   0.001373  0.011192 -0.006915 -0.002013  0.013629 -0.003676 -0.000692   \n",
              "1  -0.119522 -0.031345  0.009578  0.025178  0.001179 -0.003694 -0.000831   \n",
              "2   0.008997  0.006984  0.000782 -0.008695 -0.002614  0.001377 -0.001127   \n",
              "3  -0.063115 -0.130317  0.004896 -0.595702  0.003101  0.137438  0.004664   \n",
              "4  -0.088741 -0.093688 -0.011115  0.449010  0.005249  0.034566 -0.011399   \n",
              "5   0.006155  0.106089 -0.014223  0.692708 -0.001059 -0.265431 -0.009599   \n",
              "6  -0.004530 -0.001549 -0.001331 -0.007098 -0.001173  0.007710 -0.001390   \n",
              "7   1.000000  0.179020  0.001646 -0.004083 -0.002466 -0.050683  0.009363   \n",
              "8   0.179020  1.000000 -0.003575 -0.190351  0.000494 -0.224571  0.002086   \n",
              "9   0.001646 -0.003575  1.000000 -0.008210 -0.008811  0.001816 -0.002591   \n",
              "10 -0.004083 -0.190351 -0.008210  1.000000 -0.000235 -0.570510 -0.009929   \n",
              "11 -0.002466  0.000494 -0.008811 -0.000235  1.000000 -0.000350  0.000069   \n",
              "12 -0.050683 -0.224571  0.001816 -0.570510 -0.000350  1.000000  0.001289   \n",
              "13  0.009363  0.002086 -0.002591 -0.009929  0.000069  0.001289  1.000000   \n",
              "14 -0.445947 -0.557816 -0.009123  0.189545  0.002990  0.115045 -0.007451   \n",
              "15 -0.003108 -0.010159  0.001540 -0.004702  0.003332  0.003445 -0.009769   \n",
              "16  0.151554  0.127241  0.002023 -0.209273  0.002958 -0.010933  0.004805   \n",
              "0  -0.115344  0.118247 -0.004370 -0.044794 -0.002955 -0.050418  0.007336   \n",
              "\n",
              "          14        15        16         0  \n",
              "0  -0.003278 -0.002583  0.005674  0.006847  \n",
              "1  -0.528225  0.006554  0.144510 -0.071429  \n",
              "2   0.002603  0.004943  0.004756  0.004059  \n",
              "3   0.087543  0.005941 -0.088239  0.040137  \n",
              "4   0.352633 -0.004484 -0.000975 -0.002967  \n",
              "5   0.294021 -0.010747 -0.510255  0.031676  \n",
              "6   0.004010  0.003445 -0.012244  0.000622  \n",
              "7  -0.445947 -0.003108  0.151554 -0.115344  \n",
              "8  -0.557816 -0.010159  0.127241  0.118247  \n",
              "9  -0.009123  0.001540  0.002023 -0.004370  \n",
              "10  0.189545 -0.004702 -0.209273 -0.044794  \n",
              "11  0.002990  0.003332  0.002958 -0.002955  \n",
              "12  0.115045  0.003445 -0.010933 -0.050418  \n",
              "13 -0.007451 -0.009769  0.004805  0.007336  \n",
              "14  1.000000  0.000775  0.056679  0.046642  \n",
              "15  0.000775  1.000000  0.001515 -0.001225  \n",
              "16  0.056679  0.001515  1.000000  0.008028  \n",
              "0   0.046642 -0.001225  0.008028  1.000000  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001899</td>\n",
              "      <td>-0.003644</td>\n",
              "      <td>-0.001619</td>\n",
              "      <td>-0.000218</td>\n",
              "      <td>0.000595</td>\n",
              "      <td>0.000947</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>0.011192</td>\n",
              "      <td>-0.006915</td>\n",
              "      <td>-0.002013</td>\n",
              "      <td>0.013629</td>\n",
              "      <td>-0.003676</td>\n",
              "      <td>-0.000692</td>\n",
              "      <td>-0.003278</td>\n",
              "      <td>-0.002583</td>\n",
              "      <td>0.005674</td>\n",
              "      <td>0.006847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001899</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.013619</td>\n",
              "      <td>0.026846</td>\n",
              "      <td>0.156286</td>\n",
              "      <td>-0.532279</td>\n",
              "      <td>-0.011862</td>\n",
              "      <td>-0.119522</td>\n",
              "      <td>-0.031345</td>\n",
              "      <td>0.009578</td>\n",
              "      <td>0.025178</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>-0.003694</td>\n",
              "      <td>-0.000831</td>\n",
              "      <td>-0.528225</td>\n",
              "      <td>0.006554</td>\n",
              "      <td>0.144510</td>\n",
              "      <td>-0.071429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.003644</td>\n",
              "      <td>-0.013619</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006683</td>\n",
              "      <td>-0.002436</td>\n",
              "      <td>0.000619</td>\n",
              "      <td>0.013646</td>\n",
              "      <td>0.008997</td>\n",
              "      <td>0.006984</td>\n",
              "      <td>0.000782</td>\n",
              "      <td>-0.008695</td>\n",
              "      <td>-0.002614</td>\n",
              "      <td>0.001377</td>\n",
              "      <td>-0.001127</td>\n",
              "      <td>0.002603</td>\n",
              "      <td>0.004943</td>\n",
              "      <td>0.004756</td>\n",
              "      <td>0.004059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.001619</td>\n",
              "      <td>0.026846</td>\n",
              "      <td>0.006683</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.025842</td>\n",
              "      <td>-0.493383</td>\n",
              "      <td>0.002845</td>\n",
              "      <td>-0.063115</td>\n",
              "      <td>-0.130317</td>\n",
              "      <td>0.004896</td>\n",
              "      <td>-0.595702</td>\n",
              "      <td>0.003101</td>\n",
              "      <td>0.137438</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>0.087543</td>\n",
              "      <td>0.005941</td>\n",
              "      <td>-0.088239</td>\n",
              "      <td>0.040137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.000218</td>\n",
              "      <td>0.156286</td>\n",
              "      <td>-0.002436</td>\n",
              "      <td>0.025842</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.356500</td>\n",
              "      <td>-0.008852</td>\n",
              "      <td>-0.088741</td>\n",
              "      <td>-0.093688</td>\n",
              "      <td>-0.011115</td>\n",
              "      <td>0.449010</td>\n",
              "      <td>0.005249</td>\n",
              "      <td>0.034566</td>\n",
              "      <td>-0.011399</td>\n",
              "      <td>0.352633</td>\n",
              "      <td>-0.004484</td>\n",
              "      <td>-0.000975</td>\n",
              "      <td>-0.002967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000595</td>\n",
              "      <td>-0.532279</td>\n",
              "      <td>0.000619</td>\n",
              "      <td>-0.493383</td>\n",
              "      <td>0.356500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.004947</td>\n",
              "      <td>0.006155</td>\n",
              "      <td>0.106089</td>\n",
              "      <td>-0.014223</td>\n",
              "      <td>0.692708</td>\n",
              "      <td>-0.001059</td>\n",
              "      <td>-0.265431</td>\n",
              "      <td>-0.009599</td>\n",
              "      <td>0.294021</td>\n",
              "      <td>-0.010747</td>\n",
              "      <td>-0.510255</td>\n",
              "      <td>0.031676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000947</td>\n",
              "      <td>-0.011862</td>\n",
              "      <td>0.013646</td>\n",
              "      <td>0.002845</td>\n",
              "      <td>-0.008852</td>\n",
              "      <td>0.004947</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.004530</td>\n",
              "      <td>-0.001549</td>\n",
              "      <td>-0.001331</td>\n",
              "      <td>-0.007098</td>\n",
              "      <td>-0.001173</td>\n",
              "      <td>0.007710</td>\n",
              "      <td>-0.001390</td>\n",
              "      <td>0.004010</td>\n",
              "      <td>0.003445</td>\n",
              "      <td>-0.012244</td>\n",
              "      <td>0.000622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.001373</td>\n",
              "      <td>-0.119522</td>\n",
              "      <td>0.008997</td>\n",
              "      <td>-0.063115</td>\n",
              "      <td>-0.088741</td>\n",
              "      <td>0.006155</td>\n",
              "      <td>-0.004530</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.179020</td>\n",
              "      <td>0.001646</td>\n",
              "      <td>-0.004083</td>\n",
              "      <td>-0.002466</td>\n",
              "      <td>-0.050683</td>\n",
              "      <td>0.009363</td>\n",
              "      <td>-0.445947</td>\n",
              "      <td>-0.003108</td>\n",
              "      <td>0.151554</td>\n",
              "      <td>-0.115344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.011192</td>\n",
              "      <td>-0.031345</td>\n",
              "      <td>0.006984</td>\n",
              "      <td>-0.130317</td>\n",
              "      <td>-0.093688</td>\n",
              "      <td>0.106089</td>\n",
              "      <td>-0.001549</td>\n",
              "      <td>0.179020</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>-0.190351</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>-0.224571</td>\n",
              "      <td>0.002086</td>\n",
              "      <td>-0.557816</td>\n",
              "      <td>-0.010159</td>\n",
              "      <td>0.127241</td>\n",
              "      <td>0.118247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.006915</td>\n",
              "      <td>0.009578</td>\n",
              "      <td>0.000782</td>\n",
              "      <td>0.004896</td>\n",
              "      <td>-0.011115</td>\n",
              "      <td>-0.014223</td>\n",
              "      <td>-0.001331</td>\n",
              "      <td>0.001646</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.008210</td>\n",
              "      <td>-0.008811</td>\n",
              "      <td>0.001816</td>\n",
              "      <td>-0.002591</td>\n",
              "      <td>-0.009123</td>\n",
              "      <td>0.001540</td>\n",
              "      <td>0.002023</td>\n",
              "      <td>-0.004370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.002013</td>\n",
              "      <td>0.025178</td>\n",
              "      <td>-0.008695</td>\n",
              "      <td>-0.595702</td>\n",
              "      <td>0.449010</td>\n",
              "      <td>0.692708</td>\n",
              "      <td>-0.007098</td>\n",
              "      <td>-0.004083</td>\n",
              "      <td>-0.190351</td>\n",
              "      <td>-0.008210</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000235</td>\n",
              "      <td>-0.570510</td>\n",
              "      <td>-0.009929</td>\n",
              "      <td>0.189545</td>\n",
              "      <td>-0.004702</td>\n",
              "      <td>-0.209273</td>\n",
              "      <td>-0.044794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.013629</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>-0.002614</td>\n",
              "      <td>0.003101</td>\n",
              "      <td>0.005249</td>\n",
              "      <td>-0.001059</td>\n",
              "      <td>-0.001173</td>\n",
              "      <td>-0.002466</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>-0.008811</td>\n",
              "      <td>-0.000235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.000350</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.002990</td>\n",
              "      <td>0.003332</td>\n",
              "      <td>0.002958</td>\n",
              "      <td>-0.002955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-0.003676</td>\n",
              "      <td>-0.003694</td>\n",
              "      <td>0.001377</td>\n",
              "      <td>0.137438</td>\n",
              "      <td>0.034566</td>\n",
              "      <td>-0.265431</td>\n",
              "      <td>0.007710</td>\n",
              "      <td>-0.050683</td>\n",
              "      <td>-0.224571</td>\n",
              "      <td>0.001816</td>\n",
              "      <td>-0.570510</td>\n",
              "      <td>-0.000350</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.001289</td>\n",
              "      <td>0.115045</td>\n",
              "      <td>0.003445</td>\n",
              "      <td>-0.010933</td>\n",
              "      <td>-0.050418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.000692</td>\n",
              "      <td>-0.000831</td>\n",
              "      <td>-0.001127</td>\n",
              "      <td>0.004664</td>\n",
              "      <td>-0.011399</td>\n",
              "      <td>-0.009599</td>\n",
              "      <td>-0.001390</td>\n",
              "      <td>0.009363</td>\n",
              "      <td>0.002086</td>\n",
              "      <td>-0.002591</td>\n",
              "      <td>-0.009929</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.001289</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.007451</td>\n",
              "      <td>-0.009769</td>\n",
              "      <td>0.004805</td>\n",
              "      <td>0.007336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.003278</td>\n",
              "      <td>-0.528225</td>\n",
              "      <td>0.002603</td>\n",
              "      <td>0.087543</td>\n",
              "      <td>0.352633</td>\n",
              "      <td>0.294021</td>\n",
              "      <td>0.004010</td>\n",
              "      <td>-0.445947</td>\n",
              "      <td>-0.557816</td>\n",
              "      <td>-0.009123</td>\n",
              "      <td>0.189545</td>\n",
              "      <td>0.002990</td>\n",
              "      <td>0.115045</td>\n",
              "      <td>-0.007451</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000775</td>\n",
              "      <td>0.056679</td>\n",
              "      <td>0.046642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.002583</td>\n",
              "      <td>0.006554</td>\n",
              "      <td>0.004943</td>\n",
              "      <td>0.005941</td>\n",
              "      <td>-0.004484</td>\n",
              "      <td>-0.010747</td>\n",
              "      <td>0.003445</td>\n",
              "      <td>-0.003108</td>\n",
              "      <td>-0.010159</td>\n",
              "      <td>0.001540</td>\n",
              "      <td>-0.004702</td>\n",
              "      <td>0.003332</td>\n",
              "      <td>0.003445</td>\n",
              "      <td>-0.009769</td>\n",
              "      <td>0.000775</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.001515</td>\n",
              "      <td>-0.001225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.005674</td>\n",
              "      <td>0.144510</td>\n",
              "      <td>0.004756</td>\n",
              "      <td>-0.088239</td>\n",
              "      <td>-0.000975</td>\n",
              "      <td>-0.510255</td>\n",
              "      <td>-0.012244</td>\n",
              "      <td>0.151554</td>\n",
              "      <td>0.127241</td>\n",
              "      <td>0.002023</td>\n",
              "      <td>-0.209273</td>\n",
              "      <td>0.002958</td>\n",
              "      <td>-0.010933</td>\n",
              "      <td>0.004805</td>\n",
              "      <td>0.056679</td>\n",
              "      <td>0.001515</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006847</td>\n",
              "      <td>-0.071429</td>\n",
              "      <td>0.004059</td>\n",
              "      <td>0.040137</td>\n",
              "      <td>-0.002967</td>\n",
              "      <td>0.031676</td>\n",
              "      <td>0.000622</td>\n",
              "      <td>-0.115344</td>\n",
              "      <td>0.118247</td>\n",
              "      <td>-0.004370</td>\n",
              "      <td>-0.044794</td>\n",
              "      <td>-0.002955</td>\n",
              "      <td>-0.050418</td>\n",
              "      <td>0.007336</td>\n",
              "      <td>0.046642</td>\n",
              "      <td>-0.001225</td>\n",
              "      <td>0.008028</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# Separando dados em X e Y\r\n",
        "X= df.to_numpy()\r\n",
        "Y= df2.to_numpy()\r\n",
        "print(X.shape, Y.shape, df.columns)\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_TEMP,X_test,y_TEMP, y_test = train_test_split(X,Y,test_size = 0.2 , random_state = 1 )\r\n",
        "X_train,X_valid,y_train, y_valid = train_test_split(X_TEMP,y_TEMP,test_size = 0.2 , random_state = 1 )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 17) (30000, 1) Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
            "       '13', '14', '15', '16'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySFdkrc6aWC1",
        "outputId": "add36a33-172f-4938-8248-cbfd9572b1b6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "sc = StandardScaler()\r\n",
        "X_train = sc.fit_transform(X_train)\r\n",
        "X_test = sc.transform(X_test)\r\n",
        "X_valid = sc.transform(X_valid)"
      ],
      "outputs": [],
      "metadata": {
        "id": "rQUo-TJjbbH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "print(\"Shape DF:\",df.shape)\r\n",
        "print(\"Shape X_train:\",X_train.shape)\r\n",
        "print(\"Shape X_test:\",X_test.shape)\r\n",
        "print(\"Shape X_valid:\",X_valid.shape)\r\n",
        "print(\"Shape y_train:\",y_train.shape)\r\n",
        "print(\"Shape y_test:\",y_test.shape)\r\n",
        "print(\"Shape y_valid:\",y_valid.shape)\r\n",
        "type(X_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape DF: (30000, 17)\n",
            "Shape X_train: (19200, 17)\n",
            "Shape X_test: (6000, 17)\n",
            "Shape X_valid: (4800, 17)\n",
            "Shape y_train: (19200, 1)\n",
            "Shape y_test: (6000, 1)\n",
            "Shape y_valid: (4800, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z19LXYcdb_aD",
        "outputId": "5b08a01f-9851-4d37-edc4-01507244b4d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "modelo = Sequential()\r\n",
        "modelo.add(Dense(activation = \"relu\", input_dim = 17, units = 82))\r\n",
        "modelo.add(Dense(activation = \"relu\", units = 52))\r\n",
        "modelo.add(Dense(activation = \"relu\", units = 21))\r\n",
        "# modelo.add(Dense(activation = \"softmax\", units = 7))\r\n",
        "# modelo.add(Dense(activation = \"sigmoid\", units = 1, \r\n",
        "#                      kernel_initializer = \"uniform\"))\r\n",
        "modelo.add(Dense(7, activation='softmax'))\r\n",
        "modelo.compile(optimizer = 'SGD' , loss = 'categorical_crossentropy', \r\n",
        "                   metrics = ['accuracy'] )\r\n",
        "modelo.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 82)                1476      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 52)                4316      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 21)                1113      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 7)                 154       \n",
            "=================================================================\n",
            "Total params: 7,059\n",
            "Trainable params: 7,059\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNmewHJ9b-SF",
        "outputId": "3fd7c9af-cf68-45a9-a6a1-d3509dbf3f73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# modelo.fit(X_train , y_train ,epochs = 10)\r\n",
        "checkpointer = ModelCheckpoint(filepath='checkpoint_5-2.hdf5', verbose=1,  save_best_only=True, monitor='val_accuracy')\r\n",
        "\r\n",
        "hist = modelo.fit(X_train, y_train, batch_size=150, epochs=15, validation_data=(X_valid, y_valid), callbacks=[checkpointer], verbose=1, shuffle=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:748 train_step\n        loss = self.compiled_loss(\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (150, 1) and (150, 7) are incompatible\n",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-53a61b4a3a9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'checkpoint_5-1.hdf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:748 train_step\n        loss = self.compiled_loss(\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (150, 1) and (150, 7) are incompatible\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_cE5ndtcCJZ",
        "outputId": "0540423a-d624-4fdf-b279-2a185d0e23d4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(1)\r\n",
        "plt.plot(hist.history['accuracy'])\r\n",
        "plt.plot(hist.history['val_accuracy'])\r\n",
        "plt.title('model accuracy')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "scores = modelo.evaluate(X_test, y_test)\r\n",
        "print(\"\\n%s: %.2f%%\" % (modelo.metrics_names[1], scores[1]*100))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZEmVOoScDlp",
        "outputId": "9f2a25aa-3452-495d-bc8a-6d3c47cc1770"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "scores = modelo.evaluate(X_train, y_train)\r\n",
        "print(\"\\n%s: %.2f%%\" % (modelo.metrics_names[1], scores[1]*100))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf71UzLpcTRN",
        "outputId": "a90903bc-1b7b-419a-ae47-e06c70891511"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "scores = modelo.evaluate(X_valid, y_valid)\r\n",
        "print(\"\\n%s: %.2f%%\" % (modelo.metrics_names[1], scores[1]*100))"
      ],
      "outputs": [],
      "metadata": {
        "id": "f-wYHK05hWMb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}